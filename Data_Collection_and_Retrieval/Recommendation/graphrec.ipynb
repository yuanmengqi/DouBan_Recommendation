{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from utils import collate_fn\n",
    "from graph_rec_model import GraphRec\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读loaded_data取保存的 CSV 文件\n",
    "loaded_data = pd.read_csv('data\\\\book_score.csv')\n",
    "\n",
    "# 显示加载的数据\n",
    "print(loaded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据graphrec构建数据表，分为以下若干\n",
    "+ u_items_list：用户交互过的所有item以及评分\n",
    "+ i_users_list：item交互过的所有用户以及评分\n",
    "+ u_users_list：用户的社交网络\n",
    "+ u_users_items_list：用户的社交关系的交互物品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_mapping(id_list):\n",
    "    # 从ID列表中删除重复项并创建一个排序的列表\n",
    "    unique_ids = sorted(set(id_list))\n",
    "    \n",
    "    # 创建将原始ID映射到连续索引的字典\n",
    "    id_to_idx = {id: idx for idx, id in enumerate(unique_ids, start = 1)}\n",
    "    \n",
    "    # 创建将连续索引映射回原始ID的字典\n",
    "    idx_to_id = {idx: id for id, idx in id_to_idx.items()}\n",
    "    \n",
    "    return id_to_idx, idx_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = loaded_data['User'].unique()\n",
    "book_ids = loaded_data['Book'].unique()\n",
    "\n",
    "user_to_idx, idx_to_user = create_id_mapping(user_ids)\n",
    "book_to_idx, idx_to_book = create_id_mapping(book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_items_list, i_users_list = [(0, 0)], [(0, 0)]\n",
    "loaded_data['user_map'] = loaded_data['User'].map(user_to_idx)\n",
    "loaded_data['book_map'] = loaded_data['Book'].map(book_to_idx)\n",
    "\n",
    "# 按映射后的用户 ID 分组\n",
    "grouped_user = loaded_data.groupby('user_map')\n",
    "grouped_book = loaded_data.groupby('book_map')\n",
    "\n",
    "# 遍历排序后的分组\n",
    "for user, group in tqdm(grouped_user):\n",
    "    books = group['book_map'].tolist()\n",
    "    rates = group['Rate'].tolist()\n",
    "    \n",
    "    u_items_list.append([(book, rate) for book, rate in zip(books, rates)])\n",
    "\n",
    "for book, group in tqdm(grouped_book):\n",
    "    users = group['user_map'].tolist()\n",
    "    rates = group['Rate'].tolist()\n",
    "    \n",
    "    i_users_list.append([(user, rate) for user, rate in zip(users, rates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个空字典来存储社交关系\n",
    "contact = {}\n",
    "\n",
    "# 打开文件并读取内容\n",
    "with open('data\\Contacts.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # 分割每一行的内容\n",
    "        user, friends = line.strip().split(':')\n",
    "        # 将朋友列表转换为整数列表\n",
    "        if int(user) in user_to_idx:\n",
    "            friends_list = [user_to_idx[int(friend)] for friend in friends.split(',') if int(friend) in user_to_idx]\n",
    "            # 将朋友列表添加到字典中\n",
    "            contact[user_to_idx[int(user)]] = friends_list\n",
    "\n",
    "contact_sorted = {k: v for k, v in sorted(contact.items())}\n",
    "# 打印字典的内容\n",
    "print(contact_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_users_list, u_users_items_list = [0], [[(0, 1)]]\n",
    "\n",
    "# 按顺序遍历字典\n",
    "for user, friends in tqdm(contact_sorted.items()):\n",
    "    u_users_list.append(friends)\n",
    "    u_users_items_list.append([u_items_list[uid] for uid in friends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRatingDataset(Dataset):\n",
    "\tdef __init__(self, data, user_to_idx, book_to_idx, u_items_list, u_users_list, u_users_items_list, i_users_list):\n",
    "\t\tself.data = data\n",
    "\t\tself.user_to_idx = user_to_idx\n",
    "\t\tself.book_to_idx = book_to_idx\n",
    "\t\tself.u_items_list = u_items_list\n",
    "\t\tself.u_users_list = u_users_list\n",
    "\t\tself.u_users_items_list = u_users_items_list\n",
    "\t\tself.i_users_list = i_users_list\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\trow = self.data.iloc[index]\n",
    "\t\tuser = self.user_to_idx[row['User']]\n",
    "\t\tbook = self.book_to_idx[row['Book']]\n",
    "\t\trating = row['Rate'].astype(np.float32)\n",
    "\t\tu_items = self.u_items_list[user]\n",
    "\t\tu_users = self.u_users_list[user]\n",
    "\t\tu_users_items = self.u_users_items_list[user]\n",
    "\t\ti_users = self.i_users_list[book]\n",
    "\n",
    "\t\treturn (user, book, rating), u_items, u_users, u_users_items, i_users\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按用户分组计算NDCG\n",
    "def compute_ndcg(group):\n",
    "    true_ratings = group['true'].tolist()\n",
    "    pred_ratings = group['pred'].tolist()\n",
    "    return ndcg_score([true_ratings], [pred_ratings], k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_data, test_data = train_test_split(loaded_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# 创建训练集和测试集的数据集对象\n",
    "train_dataset = BookRatingDataset(train_data, user_to_idx, book_to_idx, u_items_list, u_users_list, u_users_items_list, i_users_list)\n",
    "test_dataset = BookRatingDataset(test_data, user_to_idx, book_to_idx, u_items_list, u_users_list, u_users_items_list, i_users_list)\n",
    "\n",
    "# 创建训练集和测试集的数据加载器\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4096, shuffle=True, collate_fn = collate_fn, drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4096, shuffle=False, collate_fn = collate_fn, drop_last = True)\n",
    "\n",
    "num_users = loaded_data['User'].nunique()  # 假设有1000个用户\n",
    "num_books = loaded_data['Book'].nunique()   # 假设有500本书\n",
    "embedding_dim = 32\n",
    "\n",
    "model = GraphRec(num_users + 1, num_books + 1, 7, embedding_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss_train, total_loss_test = 0.0, 0.0\n",
    "\n",
    "    for idx, (user_ids, book_ids, ratings, u_items, u_users, u_users_items, i_users) in tqdm(enumerate(train_dataloader)):\n",
    "        # 使用user_ids, book_ids, ratings进行训练\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(user_ids.to(device), book_ids.to(device), u_items.to(device), u_users.to(device), u_users_items.to(device), i_users.to(device))\n",
    "        loss = criterion(predictions.squeeze(1), ratings.to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "        \n",
    "        # if idx % 100 == 0:\n",
    "        #     print(f'Step {idx}, Loss: {loss.item()}')\n",
    "    output_loss_train = total_loss_train / (idx + 1)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (user_ids, item_ids, true_ratings, u_items, u_users, u_users_items, i_users) in enumerate(test_dataloader):\n",
    "            pred_ratings = model(user_ids.to(device), book_ids.to(device), u_items.to(device), u_users.to(device), u_users_items.to(device), i_users.to(device))\n",
    "\n",
    "            loss = criterion(pred_ratings.squeeze(1), ratings.to(device))\n",
    "            total_loss_test += loss.item()\n",
    "            # 将结果转换为 numpy arrays\n",
    "            user_ids_np = user_ids.long().cpu().numpy().reshape(-1, 1)\n",
    "            pred_ratings_np = pred_ratings.cpu().numpy().reshape(-1, 1)\n",
    "            true_ratings_np = true_ratings.numpy().reshape(-1, 1)\n",
    "\n",
    "            # 将这三个 arrays 合并成一个 2D array\n",
    "            batch_results = np.column_stack((user_ids_np, pred_ratings_np, true_ratings_np))\n",
    "\n",
    "            # 将这个 2D array 添加到 results\n",
    "            results.append(batch_results)\n",
    "\n",
    "        # 将结果的 list 转换为一个大的 numpy array\n",
    "        results = np.vstack(results)\n",
    "\n",
    "        # 将结果转换为DataFrame\n",
    "        results_df = pd.DataFrame(results, columns=['user', 'pred', 'true'])\n",
    "        results_df['user'] = results_df['user'].astype(int)\n",
    "\n",
    "        ndcg_scores = results_df.groupby('user').apply(compute_ndcg)    \n",
    "\n",
    "        # 计算平均NDCG\n",
    "        avg_ndcg = ndcg_scores.mean()\n",
    "        print(f'Epoch {epoch}, Loss: {output_loss_train}, MSE loss:, {total_loss_test / (idx + 1)}, Average NDCG: {avg_ndcg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
